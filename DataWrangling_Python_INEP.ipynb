{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4da7554",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# É necessário que tenha o pandas e o prettytable instalados, caso não tenha realizar o pip abaixo:\n",
    "# pip install prettytable\n",
    "# pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff44325",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importando os pacotes\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable\n",
    "from itertools import zip_longest\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209e51fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importando os dados dos arquivos, já eliminando cabeçalho e rodapé na abertura\n",
    "atu = pd.read_excel(\"ATU_ESCOLAS_2021.xlsx\", skiprows=8, nrows=174179)\n",
    "dsu = pd.read_excel(\"DSU_ESCOLAS_2021.xlsx\", skiprows=9, nrows=178126)\n",
    "had = pd.read_excel(\"HAD_ESCOLAS_2021.xlsx\", skiprows=8, nrows=151777)\n",
    "icg = pd.read_excel(\"ICG_ESCOLAS_2021.xlsx\", skiprows=10, nrows=178370)\n",
    "ird = pd.read_excel(\"IRD_ESCOLAS_2021.xlsx\", skiprows=10, nrows=165853)\n",
    "tdi = pd.read_excel(\"TDI_ESCOLAS_2021.xlsx\", skiprows=8, nrows=130112)\n",
    "txr = pd.read_excel(\"TX_REND_ESCOLAS_2021.xlsx\", skiprows=8, nrows=130129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808fd611",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Utilizado para remover os warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Usado para plotar na célula ao invés de abrir uma nova janela\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c2c05c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Função para mostrar a estrutura de colunas do dataframe\n",
    "# dataframes = Lista com dataframes\n",
    "# cabeçalhos = Lista com cabeçalhos\n",
    "# nlinhas = Quantidade máxima de linhas\n",
    "def mostrar_estrutura(dataframes, cabecalhos, nlinhas):\n",
    "    tabelas = []\n",
    "    for df, cabecalho in zip(dataframes, cabecalhos):\n",
    "        colunas = df.columns.tolist()\n",
    "        tabela = PrettyTable()\n",
    "        tabela.field_names = [f\"DataFrame {cabecalho}\"]\n",
    "\n",
    "        # Adicione as colunas até o máximo de linhas\n",
    "        while len(colunas) < nlinhas:\n",
    "            colunas.append(\"\")  # Adicione uma linha vazia\n",
    "\n",
    "        tabela.add_row([\"\\n\".join(colunas)])\n",
    "        tabelas.append(tabela)\n",
    "\n",
    "    # Combina as linhas das tabelas\n",
    "    linha_combinada = list(zip_longest(*[str(tabela).splitlines() for tabela in tabelas], fillvalue=''))\n",
    "\n",
    "    # Imprime as tabelas lado a lado\n",
    "    for linha in linha_combinada:\n",
    "        print(' '.join(linha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf7bed0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Chamando a funcão para mostrar a estrutura de 5 arquivos\n",
    "mostrar_estrutura([txr, atu, had, tdi, dsu], [\"TXR\", \"ATU\", \"HAD\", \"TDI\", \"DSU\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e95909",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Deixando apenas as variáveis necessárias\n",
    "atu = atu.iloc[:, [1,2,4,5,6,7,8,12,25]]\n",
    "dsu = dsu.iloc[:, [1,2,4,5,6,7,8,12,15]]\n",
    "had = had.iloc[:, [1,2,4,5,6,7,8,12,24]]\n",
    "icg = icg.iloc[:, [1,2,4,5,6,7,8,9]]\n",
    "ird = ird.iloc[:, [1,2,4,5,6,7,8,9]]\n",
    "tdi = tdi.iloc[:, [1,2,4,5,6,7,8,9,21]]\n",
    "txr = txr.iloc[:, [1,2,4,5,6,7,8,9,21]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4059579a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Renomear variaveis\n",
    "# Foi criada uma lista com o nome das variáveis da chave composta\n",
    "colunas = ['regiao', 'uf', 'municipio', 'id_escola', 'escola', 'categoria', 'dependencia']\n",
    "\n",
    "atu.columns = colunas + ['vr_fun_atu', 'vr_med_atu']\n",
    "dsu.columns = colunas + ['vr_fun_dsu', 'vr_med_dsu']\n",
    "had.columns = colunas + ['vr_fun_had', 'vr_med_had']\n",
    "icg.columns = colunas + ['nivel']\n",
    "ird.columns = colunas + ['vr_ird']\n",
    "tdi.columns = colunas + ['vr_fun_tdi', 'vr_med_tdi']\n",
    "txr.columns = colunas + ['vr_fun_txr', 'vr_med_txr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06583c70",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Chamando a funcão para mostrar a estrutura de todos os arquivos após os ajustes\n",
    "mostrar_estrutura([txr, atu, had, tdi, dsu], [\"TXR\", \"ATU\", \"HAD\", \"TDI\", \"DSU\"], 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f68b46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Unindo os dataframes em um único (juntando tudo)\n",
    "# Realizar o join dos DataFrames (usamos a lista com as colunas da chave composta)\n",
    "colunas_para_merge = colunas\n",
    "dataframes = [txr, atu, had, tdi, dsu, icg, ird]\n",
    "# Começar com o primeiro DataFrame\n",
    "df_inep = dataframes[0]\n",
    "# Realizar o join dos DataFrames usando as colunas em comum como chave\n",
    "for df in dataframes[1:]:\n",
    "    df_inep = pd.merge(df_inep, df, on=colunas_para_merge, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01e19c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verificar a estrutura do df_inep\n",
    "mostrar_estrutura([df_inep], [\"DF_INEP\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b4912",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verificando o total de registros antes da preparação dos dados\n",
    "qt_antes = len(df_inep)\n",
    "print(f\"Qt antes: {qt_antes} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8fc56b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remover registros que contenham \"--\" e NaN\n",
    "#Substituir '--' por NaN para facilitar a remoção\n",
    "df_inep = df_inep.replace('--', pd.NA)\n",
    "# Remover as linhas que contêm pelo menos um NaN (anteriormente '--')\n",
    "df_inep = df_inep.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90c95d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Remover possíveis linhas duplicadas,mantendo a primeira ocorrência\n",
    "df_inep = df_inep.drop_duplicates(subset= colunas, keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af06d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verificando o total de registros após a preparação dos dados\n",
    "qt_apos = len(df_inep)\n",
    "qt_removido = qt_antes - qt_apos\n",
    "qt_duplicados = qt_apos - df_inep['id_escola'].nunique()\n",
    "print(f\"Qt. antes: {qt_antes}, Qt após: {qt_apos}, Qt removidos: {qt_removido}, Qt duplicados: {qt_duplicados}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac50a23",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Listando os types das colunas\n",
    "df_inep.infer_objects()\n",
    "df_inep.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e505a021",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Defina as colunas de texto como tipo string, usaremos a lista já existente em colunas\n",
    "colunas_texto = colunas + ['nivel']\n",
    "df_inep[colunas_texto] = df_inep[colunas_texto].astype(str)\n",
    "# Defina as demais colunas numéricas para terem duas casas decimais\n",
    "colunas_numericas = [coluna for coluna in df_inep.columns if coluna not in colunas_texto]\n",
    "df_inep[colunas_numericas] = df_inep[colunas_numericas].round(2).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78ea4ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "colunas_numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b123fdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Listando os types das colunas\n",
    "df_inep.infer_objects()\n",
    "df_inep.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2276bf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analisando a variavel nivel para aplicar dummyzação\n",
    "df_inep[['municipio', 'vr_ird', 'nivel']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c983c0d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dummyzando a variável nivel\n",
    "df_inep = pd.get_dummies(df_inep, columns=['nivel'], prefix=['d'])\n",
    "# Renomeando as novas colunas\n",
    "df_inep.rename(columns={\n",
    "    'd_Nível 2': 'nivel2', \n",
    "    'd_Nível 3': 'nivel3', \n",
    "    'd_Nível 4': 'nivel4',\n",
    "    'd_Nível 5': 'nivel5',\n",
    "    'd_Nível 6': 'nivel6'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5881ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Analisando a dummyzação\n",
    "colunas_dummies = ['nivel2', 'nivel3', 'nivel4', 'nivel5', 'nivel6']\n",
    "df_inep[['municipio', 'vr_ird'] + colunas_dummies].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb970aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Verificando se tem registro duplicado para a coluna id_cidade\n",
    "print(f\"Qtde registros: {len(df_inep)} - Qtde duplicados: {len(df_inep) - df_inep['id_escola'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7075e84",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Analisando antes de padronizar\n",
    "df_inep[['id_escola', 'vr_fun_txr', 'vr_med_txr', 'vr_fun_atu', 'vr_med_atu', 'nivel2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5ea82a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Padronização das variáveis\n",
    "# Atenção, pacote: from sklearn.preprocessing import StandardScaler\n",
    "# Inicialize o objeto StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# Ajuste e transforme o DataFrame (aqui usamos as duas listas que contém o que precisamos)\n",
    "colunas_a_padronizar = colunas_numericas + colunas_dummies\n",
    "# Padronize as colunas selecionadas\n",
    "df_inep[colunas_a_padronizar] = scaler.fit_transform(df_inep[colunas_a_padronizar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d635cbf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Analisando após padronizar \n",
    "df_inep[['id_escola', 'vr_fun_txr', 'vr_med_txr', 'vr_fun_atu', 'vr_med_atu', 'nivel2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13b40e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Criar os datraframes para aplicar a PCA para os ensinos fundamental e médio\n",
    "df_fundamental = df_inep[['id_escola', 'vr_fun_atu','vr_fun_dsu','vr_fun_had','vr_ird','vr_fun_tdi','vr_fun_txr'] + colunas_dummies]\n",
    "df_medio = df_inep[['id_escola', 'vr_med_atu','vr_med_dsu','vr_med_had','vr_ird','vr_med_tdi','vr_med_txr'] + colunas_dummies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53ab2d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colunas_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed84ff5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mostrar_estrutura([df_inep, df_fundamental, df_medio], [\"DF_INEP\", \"DF_FUNDAMENTAL\", \"DF_MEDIO\"], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4168b014",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_fundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4cea6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id_escola_f = df_fundamental['id_escola'].values\n",
    "id_escola_m = df_medio['id_escola'].values\n",
    "# Removendo a coluna\n",
    "df_fundamental.drop('id_escola', axis=1, inplace=True)\n",
    "df_medio.drop('id_escola', axis=1, inplace=True)\n",
    "# Nomeando os registros com o id_escola\n",
    "df_fundamental.index = id_escola_f\n",
    "df_medio.index = id_escola_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82ea699",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_fundamental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88445d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e5a0c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Removendo o indicador de desempenho de complexidade da gestão escola\n",
    "df_fundamental = df_fundamental.drop(columns=colunas_dummies)\n",
    "df_medio = df_medio.drop(columns=colunas_dummies)\n",
    "df_inep = df_inep.drop(columns=colunas_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c333c60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mostrar_estrutura([df_inep, df_fundamental, df_medio], [\"DF_INEP\", \"DF_FUNDAMENTAL\", \"DF_MEDIO\",], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbbec8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Explorando como ficaram os dataframes para o ensino fundamental e médio\n",
    "dataframes = [df_fundamental, df_medio]\n",
    "for idx, df in enumerate(dataframes, start=1):\n",
    "    print(f\"DataFrame {idx}:\\n\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\" + \"=\"*30 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb32f14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Deletando os dataframes auxiliares\n",
    "del atu\n",
    "del dsu\n",
    "del had\n",
    "del icg\n",
    "del ird\n",
    "del tdi\n",
    "del txr\n",
    "# Forçar a coleta de lixo para liberar a memória\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
